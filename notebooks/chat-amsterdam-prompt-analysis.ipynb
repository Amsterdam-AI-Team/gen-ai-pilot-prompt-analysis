{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Disclaimer:\n",
        "##### A lot of the code and plots in this notebook are meant for the analysis of close to 2000 pilot prompts by more than 100 users.\n",
        "\n",
        "##### The data within this repository only serves demo purposes and would results in less interesting or confusing plots."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### First, set up your OpenAI connection"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "AZURE_OPENAI_API_KEY = \"YOUR_API_KEY\"\n",
        "AZURE_OPENAI_API_VERSION = \"YOUR_API_VERSION_WE_USED_2023-05-15\"\n",
        "AZURE_OPENAI_ENDPOINT = \"YOUR_ENDPOINT\""
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1719493121447
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from openai import AzureOpenAI\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "client = AzureOpenAI(\n",
        "    api_key=AZURE_OPENAI_API_KEY,\n",
        "    api_version=\"2023-05-15\",\n",
        "    azure_endpoint=AZURE_OPENAI_ENDPOINT,\n",
        ")\n",
        "\n",
        "\n",
        "def prompt_gpt(prompt, context=None, system=None):\n",
        "\n",
        "    conversation = []\n",
        "\n",
        "    if system:\n",
        "        conversation.append({\"role\": \"system\", \"content\": system})\n",
        "\n",
        "    if context:\n",
        "        conversation.append({\"role\": \"system\", \"content\": context})\n",
        "\n",
        "    conversation.append({\"role\": \"user\", \"content\": prompt})\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "                    model=\"gpt-35-turbo\",\n",
        "                    messages=conversation,\n",
        "                    temperature=0.3,\n",
        "                    # max_tokens=200,\n",
        "                    top_p=0.95,\n",
        "                    frequency_penalty=0,\n",
        "                    presence_penalty=0,\n",
        "                    stop=None,\n",
        "                    # response_format={ \"type\": \"json_object\" }\n",
        "    )\n",
        "\n",
        "    finish_reason = response.choices[0].finish_reason\n",
        "    if finish_reason != \"stop\":\n",
        "        print(finish_reason)\n",
        "\n",
        "    return response.choices[0].message.content"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1719490673260
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Set up configs, paths, etc"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_folder = \"../data\"\n",
        "\n",
        "input_file= f\"{data_folder}/example_data_pilot_analysis.csv\"\n",
        "output_file_html = f\"{input_file}-analyzed-{{level}}.html\"\n",
        "output_file_csv = f\"{input_file}-analyzed-{{level}}.csv\"\n",
        "output_file_xlsx = f\"{input_file}-analyzed.xlsx\""
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1719490706368
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "from collections import defaultdict\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from nltk.tokenize import word_tokenize\n",
        "import re\n",
        "from tqdm import tqdm\n",
        "\n",
        "tqdm.pandas()\n",
        "\n",
        "logs = pd.read_csv(\n",
        "    input_file, sep=\",\", quotechar='\"', \n",
        "    on_bad_lines=\"warn\", converters={'Prompt':lambda x:x.replace('\\n\\n','')}, \n",
        "    quoting=csv.QUOTE_MINIMAL,\n",
        "    parse_dates=True,\n",
        "    date_format=\"%Y-%m-%dT%H:%M:%S.%fZ\")\n",
        "\n",
        "logs[\"LoggedAt\"] = pd.to_datetime(logs[\"LoggedAt\"], format='%Y-%m-%dT%H:%M:%S.%fZ', errors=\"ignore\")\n",
        "logs[\"promptLength\"] = logs.Prompt.map(lambda x: len(word_tokenize(x)))\n",
        "if \"Response\" in logs:\n",
        "    logs[\"responseLength\"] = logs.Response.progress_map(lambda x: len(word_tokenize(x)) if isinstance(x, str) else np.nan)\n",
        "else:\n",
        "    logs[\"responseLength\"] = np.nan"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1719490714025
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "logs"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1719490714370
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Filter only relevant dates"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "logs = logs[(logs[\"LoggedAt\"] > pd.Timestamp(2024, 2, 25)) & (logs[\"LoggedAt\"] < pd.Timestamp(2024, 6, 30))]\n",
        "logs"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1719490714753
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Group User Sessions"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "full_sessions = logs.groupby([\"cid\", \"uhash\"])[\"LoggedAt\"].agg([\"count\", \"min\", \"max\"]).reset_index()\n",
        "full_sessions[\"duration\"] = full_sessions[\"max\"] - full_sessions[\"min\"]\n",
        "\n",
        "full_sessions[\"duration_minutes\"] = \\\n",
        "    full_sessions[\"duration\"].dt.components.days * 24 * 60 + \\\n",
        "    full_sessions[\"duration\"].dt.components.hours * 60 + \\\n",
        "    full_sessions[\"duration\"].dt.components.minutes\n",
        "\n",
        "full_sessions.head()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1719490715148
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Basic Log Analysis"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Calculate a few things"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def mean(x):\n",
        "    return round(np.mean(x), 2)\n",
        "\n",
        "def std(x):\n",
        "    return round(np.std(x), 2)\n",
        "\n",
        "def median(x):\n",
        "    return round(np.median(x), 2)\n",
        "\n",
        "print(f\"Total prompts: {logs.Prompt.count()}\")\n",
        "print(f\"Unique users: {logs.uhash.nunique()}\")\n",
        "print(f\"Unique session ids: {logs.cid.nunique()}\")\n",
        "print(f\"Prompts per user: {mean(logs.uhash.value_counts())}±{std(logs.uhash.value_counts())}; Median: {median(logs.uhash.value_counts())}\")\n",
        "print(f\"Prompts per session: {mean(logs.cid.value_counts())}±{std(logs.cid.value_counts())}; Median: {median(logs.cid.value_counts())}\")\n",
        "print(f\"Session duration: {mean(full_sessions.duration_minutes)}±{std(full_sessions.duration_minutes)}; Median: {median(full_sessions.duration_minutes)}\")\n",
        "print(f\"Prompt Length: {mean(logs.promptLength)}±{std(logs.promptLength)}; Median: {median(logs.promptLength)}\")\n",
        "print(f\"Response Length: {mean(logs.responseLength)}±{std(logs.responseLength)}; Median: {median(logs.responseLength)}\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1719490715473
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prompts per user"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Reminder: Prompts per user: {mean(logs.uhash.value_counts())}±{std(logs.uhash.value_counts())}; Median: {median(logs.uhash.value_counts())}\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1719490715813
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fontsize = 25\n",
        "\n",
        "prompts_per_user = logs.uhash.value_counts().sort_values(ascending=False)\n",
        "ax = prompts_per_user.plot(kind=\"bar\", xticks=range(0, logs.uhash.nunique(), 5), figsize=(12, 9), color=[\"#00AEEF\"])\n",
        "ax.set_xlabel(\"user ID*\", fontdict={'fontsize': fontsize})\n",
        "ax.set_ylabel(\"number of prompts\", fontdict={'fontsize': fontsize})\n",
        "ax.yaxis.set_tick_params(labelsize=fontsize/2)\n",
        "ax"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1719490716198
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ax.figure.savefig(f\"{input_file}-prompts_per_user.png\", bbox_inches='tight')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1719490716429
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Usage by most active users"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "logs.uhash.value_counts().head(5)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1719490716821
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sessions per user"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "logs.groupby([\"uhash\"]).cid.nunique().sort_values(ascending=False).plot(kind=\"bar\", use_index=False, figsize=(12, 9))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1719490717321
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prompts per session"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Prompts per session: {mean(logs.cid.value_counts())}±{std(logs.cid.value_counts())}; Median: {median(logs.cid.value_counts())}\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1719490717587
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "logs.cid.value_counts().sort_values(ascending=False).plot(kind=\"bar\", xticks=range(0, logs.cid.nunique(), 20), figsize=(12, 9))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1719490717978
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Top most active users in a single conversation"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "logs.cid.value_counts().head(5)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1719490718332
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prompt Length"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Reminder: Prompt Length: {mean(logs.promptLength)}±{std(logs.promptLength)}; Median: {median(logs.promptLength)}\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1719490718695
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "logs.promptLength.sort_values(ascending=False).plot(kind=\"bar\", xticks=range(0, logs.promptLength.count(), 20), figsize=(12, 9))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1719490719276
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Inspect extremely short or long prompts\n",
        "###### Reminder: adjust lengths of interest"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "short_length = 50\n",
        "extremely_short_prompts = logs[logs.promptLength < short_length]\n",
        "extremely_short_prompts.tail(5)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1719490719721
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "long_length = 100\n",
        "extremely_long_prompts = logs[logs.promptLength > long_length]\n",
        "extremely_long_prompts"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1719490721360
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prompt Length"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Reminder: Response Length: {mean(logs.responseLength)}±{std(logs.responseLength)}; Median: {median(logs.responseLength)}\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1719490722476
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "notna_responses = logs.responseLength[logs.responseLength.notna()]\n",
        "notna_responses.sort_values(ascending=False).plot(kind=\"bar\", xticks=range(0, notna_responses.count(), 20), figsize=(12, 9))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1719490722967
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Times and intervals"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Reminder: Session duration: {mean(full_sessions.duration_minutes)}±{std(full_sessions.duration_minutes)}; Median: {median(full_sessions.duration_minutes)}\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1719490723451
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Duration of full sessions"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# full_sessions[\"duration_minutes\"].plot(kind=\"line\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1719490736469
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Sessions that last more than 1 working day (9h)"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "extremely_long_sessions = full_sessions[full_sessions.duration_minutes > 9 * 60]\n",
        "extremely_long_sessions.shape[0]"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1719490738133
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Unique users that like long sessions"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "extremely_long_sessions.uhash.nunique()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1719490778929
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Mean very long sessions: {mean(extremely_long_sessions[\"count\"])}')\n",
        "print(f'Mean not-so-long sessions: {mean(full_sessions[~full_sessions.cid.isin(extremely_long_sessions.cid)][\"count\"])}')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1719490779662
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Analyse prompt content"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define categories and prompt\n",
        "\n",
        "The task and domains were iteratively refined based on\n",
        "- a few existing lists and ontologies\n",
        "- the needs and interests of the municipality \n",
        "- the preliminary results of the prompt analysis (e.g. new categories were introduced by the model in a meaningful consructive way) \n",
        "\n",
        "\n"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Some useful prompt categories, tasks & domains that served as inspiration\n",
        "* https://txt.cohere.com/generative-ai-part-2/\n",
        "* https://github.com/tatsu-lab/stanford_alpaca#data-release\n",
        "* themes from [amsterdam.nl](amsterdam.ml)\n",
        "* tasks from start survey"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Dutch categories & prompt"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "task_types = {\n",
        "    \"Entertainment en lol\": [\"chatten\"],\n",
        "    \"Samenvatten van documenten of emails\": [\"tekst samenvatten\"],\n",
        "    \"Verbeteren/herschrijven van tekst\": [\"tekst vertalen\", \"tekst herschrijven\", \"tekst vereenvoudigen\"],\n",
        "    \"Analyseren van data zoals excel\": [\"tekst analyseren\"],\n",
        "    \"Hulp bij opstellen/ verbeteren e-mails en documenten\": [\"schrijf e-mail\", \"schrijf tekst\"],\n",
        "    \"Hulp met coderen\": [\"schrijf code\"],\n",
        "    \"Informatie vinden\": [ # // Including \"Persoonlijke ontwikkeling en studie\"\n",
        "        \"geef antwoord\", \"geef definitie\", \"geef uitleg\",\n",
        "        \"geef instructies\",\n",
        "        \"geef lijst\",\n",
        "    ],\n",
        "    \"Creatieve ideeën opdoen\": [\"geef voorbeelden\", \"geef ideeën\", \"geef mening\", \"geef advies\"],\n",
        "    \"Hulp bij technische problemen met computer of software\": [\"hulp met software\"],\n",
        "    \"Spirituele of mentale steun bij werkstress\": [\"mentale steun\"],\n",
        "    \"Other\": [\"test\", \"verzoek verduidelijken\", \"geen van toepassing\"],\n",
        "}\n",
        "\n",
        "tasks = sum(task_types.values(), [])"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1719491518047
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "domains = [\n",
        "    \"algemene kennis\", \"stadskennis\",\n",
        "    \"technologie\", \"AI\", \"programmeren\", \"wiskunde\",\n",
        "    \"productiviteit\",\n",
        "    \"belastingen\", \"financiën\", \"juridisch\", \"politiek\", \"overheid\",\n",
        "    \"openbare ruimte\", \"stedelijke ontwikkeling\", \"wonen\",\n",
        "    \"mobiliteit\", \"veiligheid\",\n",
        "    \"duurzaamheid\", \"milieu\", \"voedsel\",\n",
        "    \"gezondheid\", \"sport\",\n",
        "    \"onderwijs\",\n",
        "    # \"innovatie\",\n",
        "    \"HR\", \"sociaal\", \n",
        "    # \"inclusie\",\n",
        "    \"communicatie\",\n",
        "    # \"taal\",\n",
        "    \"geen van toepassing\",\n",
        "]"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1719491518621
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "questions = [\"ja/nee\", \"wat\", \"wie\", \"welke\", \"waar\", \"wanneer\", \"waarom\", \"hoe\", \"hoeveel\", \"kan je\"]\n",
        "\n",
        "sensitive = [\"[NAME]\", \"[BSN]\", \"[ADDRESS]\", \"[PHONE]\", \"[EMAIL]\", \"[ORGANIZATION]\"]\n",
        "risk_words = [\"sharepoint\", \"intranet\", \"burger\", \"@amsterdam.nl\"]"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1719491519386
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fields = {\n",
        "    \"topic\": {\n",
        "        \"topic\": f\"bevat het belangrijkste onderwerp van het {{granularity}}\",\n",
        "        \"task\": f\"bevat een enkele taak uit de volgende lijst die de gebruikersbehoeften het beste beschrijft: {tasks}. Kom niet met nieuwe taken.\",\n",
        "        \"domain\": f\"bevat één woord uit de volgende lijst dat het domein het beste beschrijft: {domains}. Bedenk geen nieuwe domeinen.\",\n",
        "    },\n",
        "    \"question\": {\n",
        "        \"factual\": f\"een bolean waar/onwaar - of deze {{granularity}} om feitelijke informatie vraagt (bijvoorbeeld wie momenteel een rol vervult, of waar iets te vinden is).\",\n",
        "        \"question\": f\"als de {{granularity}} een vraag bevat, welk vraagwoord uit de volgende lijst beschrijft deze het beste: {questions}. Als er geen van toepassing zijn, retourneert u een lege tekenreeks.\",\n",
        "    },\n",
        "    \"risk_general\": {\n",
        "        \"risk\": f\"een boolean waar/onwaar - of dit een mogelijk riskante {{granularity}} is die persoonlijke gegevens of gevoelige bedrijfsinformatie bevat.\",\n",
        "        \"risk_word\": f\"een lijst met alle woorden die kunnen aantonen dat dit een mogelijk riskante, onethische of schadelijke {{granularity}} is.\",\n",
        "        \"harmful\": f\"een booleaanse waar/onwaar - of dit nu een mogelijk onethische of schadelijke aanwijzing is, die in tegenspraak is met onze waarden van inclusiviteit, openheid, rechtvaardigheid en integriteit.\",\n",
        "    },\n",
        "    \"risk_concrete\": {\n",
        "        \"namen\": f\"alle persoonlijke namen die in de {{granularity}} voorkomen.\",\n",
        "        \"organisaties\": f\"alle namen van organisaties die in de {{granularity}} voorkomen.\",\n",
        "        \"adressen\": f\"alle adressen die in de {{granularity}} voorkomen (inclusief persoonlijke- of werkadressen).\",\n",
        "        \"emails\": f\"alle e-mail adressen die in de {{granularity}} voorkomen.\",\n",
        "        \"inloggegevens\": f\"alle inloggegevens die in de {{granularity}} voorkomen (inclusief gebruikersnamen en wachtwoorden).\",\n",
        "        \"geboortedata\": f\"alle geboortedata die in de {{granularity}} voorkomen\",\n",
        "        \"identificatienummers\": f\"alle nummers die in de {{granularity}} voorkomen (inclusief BSN's, paspoort- of rijbewijsnummers, IP-adressen).\",\n",
        "        \"nummers\": f\"alle nummers die in de {{granularity}} voorkomen (inclusief telefoonnummers, bankrekeningnummer, salarisgegevens).\",\n",
        "        \"urls\": f\"alle URLs die in de {{granularity}} voorkomen.\",\n",
        "        # \"sociale identiteit\": f\"alle ras- of etniciteitswoorden woorden die in de {{granularity}} voorkomen.\",\n",
        "        \"sociale identiteit\": f\"alle woorden met betrekking tot ras of etniciteit, religie of levensbeschouwing, politieke voorkeur, geslacht of seksuele geaardheid.\",\n",
        "        \"gezondheid\": f\"alle gezondheidsinformatie\",\n",
        "    }\n",
        "}"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1719491520004
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_template_general = f\"\"\"\n",
        "Ik zal u {{input_description}} geven van een chatsysteem.\n",
        "Geef mij voor deze {{granularity}} een enkele geformatteerd json-object terug dat de volgende velden bevat:\n",
        "<<FIELDS>>\n",
        "-----\n",
        "De {{granularity}} is:\n",
        "\n",
        "\"{{input}}\"\n",
        "-----\n",
        "De geformatteerd json-object is:\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "prompts = {\n",
        "    field_type: prompt_template_general.replace(\n",
        "        \"<<FIELDS>>\", \"\\n\\n\".join([f'\"{field}\": {description}' for field, description in fields[field_type].items()])\n",
        "    ) for field_type in fields.keys()\n",
        "}"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1719491520847
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_description = \"een gebruikersprompt\"\n",
        "granularity = \"prompt\"\n",
        "# print(prompts[\"risk_concrete\"].format(input_description=input_description, granularity=granularity, input=\"{input}\" ).replace(\"\\n\\n\", \"\\n\"))\n",
        "# print(prompts[\"risk_general\"].format(input_description=input_description, granularity=granularity, input=\"{input}\" ).replace(\"\\n\\n\", \"\\n\"))\n",
        "print(prompts[\"topic\"].format(input_description=input_description, granularity=granularity, input=\"{input}\" ).replace(\"\\n\\n\", \"\\n\"))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1719491523436
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def jsonify_response(response):\n",
        "    # sometimes there's extra \"opmerkingen\" and so on after the jsons\n",
        "    shortened = response.split(\"}\")[0] + \"}\"\n",
        "    # sometimes json doesn't get loaded due to funky white spaces around\n",
        "    jsonified = json.loads(re.sub(r\",[\\n\\s\\t]\\}\", \"\\n}\", shortened).strip())\n",
        "    # sometimes model returns some nonsense fields we don't care about\n",
        "    long_keys = list(filter(lambda x: len(x) > 20, jsonified.keys()))\n",
        "    if long_keys:\n",
        "        print(f\"Ignoring {long_keys}\")\n",
        "    return {key: val for key, val in jsonified.items() if key not in long_keys}\n",
        "    # return {key: val for key, val in jsonified.items() if key in preserve_fields}"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1719491599350
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Run on prompt level"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    df = pd.read_csv(output_file_csv.format(level=\"prompt\"), index_col=0)\n",
        "\n",
        "except:\n",
        "    df = pd.DataFrame()\n",
        "\n",
        "    input_description = \"een gebruikersprompt\"\n",
        "    granularity = \"prompt\"\n",
        "\n",
        "    individual_broken = defaultdict(int)\n",
        "\n",
        "    #for test_prompt in tqdm(individual_prompts):\n",
        "    for idx, entry in tqdm(logs.iterrows(), total=logs.shape[0]):\n",
        "        test_prompt = entry[\"Prompt\"]\n",
        "        response_dict = entry[[\"Prompt\", \"cid\", \"uhash\", \"LoggedAt\", \"promptLength\"]].to_dict()\n",
        "        if entry[\"promptLength\"] < 15:\n",
        "            response_dict.update({\"skipped-prompt\": \"prompt-too-short\"})\n",
        "        else:\n",
        "            for topic, topic_prompt in prompts.items():\n",
        "                try:\n",
        "                    analysis_prompt = topic_prompt.format(input_description=input_description, granularity=granularity, input=test_prompt)\n",
        "                    response = prompt_gpt(prompt = analysis_prompt)\n",
        "                    response_dict.update(jsonify_response(response)) \n",
        "                    # display(pd.DataFrame.from_dict(response_dict))\n",
        "                except Exception as e:\n",
        "                    individual_broken[topic] += 1\n",
        "                    response_dict.update({f\"skipped-{topic}\": str(e)})\n",
        "                    print(\"====================\")\n",
        "                    print(topic, e)\n",
        "                    print(test_prompt)\n",
        "                    print(response)\n",
        "                    print(\"====================\")\n",
        "        df = pd.concat([df, pd.DataFrame.from_dict([response_dict])])\n",
        "\n",
        "    print(f\"Broken: {individual_broken}\")\n",
        "\n",
        "    df[\"LoggedAt\"] = df[\"LoggedAt\"].dt.date\n",
        "    df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "df.head(2)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1719492586447
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " ### Same logic but on session level\n",
        "### DISCLAIMER: The analysis did not work well on session level due to the misunderstanding of the conversation feature and the (ab)use of sessions for multiple conversations"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    session_df = pd.read_csv(output_file_csv.format(level=\"session\"), index_col=0)\n",
        "\n",
        "except:\n",
        "    session_df = pd.DataFrame()\n",
        "\n",
        "    input_description = \"de gebruikersprompten van een gesprek\"\n",
        "    granularity = \"gesprek\"\n",
        "\n",
        "    session_broken = defaultdict(int)\n",
        "\n",
        "    session_prompts = logs.groupby([\"cid\", \"uhash\", logs[\"LoggedAt\"].dt.date])[\"Prompt\"].agg(lambda x: \"\\n\".join(x)).reset_index()\n",
        "\n",
        "    # for test_prompt in tqdm(session_prompts):\n",
        "    for idx, entry in tqdm(session_prompts.iterrows(), total=session_prompts.shape[0]):\n",
        "        response_dict = entry.to_dict()\n",
        "        test_prompt = entry[\"Prompt\"]\n",
        "        if len(test_prompt) < 15:\n",
        "            response_dict.update({\"skipped-session\": \"session-too-short\"})\n",
        "        else:\n",
        "            for topic, topic_prompt in prompts.items():\n",
        "                try:\n",
        "                    analysis_prompt = topic_prompt.format(input_description=input_description, granularity=granularity, input=test_prompt)\n",
        "                    response = prompt_gpt(prompt = analysis_prompt)\n",
        "                    response_dict.update(jsonify_response(response)) \n",
        "                    # display(pd.DataFrame.from_dict(response_dict))\n",
        "                except Exception as e:\n",
        "                    session_broken[topic] += 1\n",
        "                    response_dict.update({f\"skipped-{topic}\": str(e)})\n",
        "                    print(\"====================\")\n",
        "                    print(topic, e)\n",
        "                    print(test_prompt)\n",
        "                    print(response)\n",
        "                    print(\"====================\")\n",
        "        session_df = pd.concat([session_df, pd.DataFrame.from_dict([response_dict])])\n",
        "\n",
        "    print(f\"Broken: {session_broken}\")\n",
        "    session_df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "session_df.tail(2)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1719492688156
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fix some common inconsistencies\n",
        "\n",
        "##### Adjust based on own data\n",
        "##### In our case, there were often english terms in between the Dutch ones"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for field in [\"task\", \"domain\", \"question\"]:\n",
        "    df[field] = df[field].str.lower()\n",
        "\n",
        "\n",
        "for field in [\"task\", \"domain\", \"question\"]:\n",
        "    session_df[field] = session_df[field].str.lower()\n",
        "\n",
        "\n",
        "domain_map = {\n",
        "    \"general knowledge\": \"algemene kennis\",\n",
        "    \"mode\": \"algemene kennis\",\n",
        "    \"muziek\": \"algemene kennis\",\n",
        "    \"cultuur\": \"algemene kennis\",\n",
        "    \"wetenschap\": \"algemene kennis\",\n",
        "    \"city knowledge\": \"stadskennis\",\n",
        "\n",
        "    \"taal\": \"communicatie\",\n",
        "\n",
        "    \"technology\": \"technologie\",\n",
        "    \"gis\": \"programmeren\",\n",
        "    \"programming\": \"programmeren\",\n",
        "\n",
        "    \"natuur\": \"milieu\",\n",
        "    # \"milieu\": \"duurzamheid\",\n",
        "\n",
        "    \"statistiek\": \"wiskunde\",\n",
        "}\n",
        "\n",
        "for original, correct in domain_map.items():\n",
        "    df.domain = df.domain.map(lambda x: correct if x == original else x)\n",
        "    session_df.domain = session_df.domain.map(lambda x: correct if x == original else x)\n",
        "\n",
        "task_map = {\n",
        "    \"geef samenvatting\": \"tekst samenvatten\",\n",
        "    \"text summarization\": \"tekst samenvatten\",\n",
        "    \"text rewriting\": \"tekst samenvatten\",\n",
        "    \"give answer\": \"geef antwoord\",\n",
        "    \"answer question\": \"geef antwoord\",\n",
        "    \"beantwoord vraag\": \"geef antwoord\",\n",
        "    # \"geef voordelen voor gebruiker en gemeente\": \"\",\n",
        "    # \"geef voorbeeld\": \"\",\n",
        "    \"explain\": \"geef uitleg\",\n",
        "}\n",
        "\n",
        "for original, correct in task_map.items():\n",
        "    df.task = df.task.map(lambda x: correct if x == original else x)\n",
        "    session_df.task = session_df.task.map(lambda x: correct if x == original else x)\n",
        "\n",
        "df.task = df.task.map(lambda x: \"geef voorbeelden\" if (isinstance(x, str) and \"voorbeeld\" in x) else x)\n",
        "session_df.task = session_df.task.map(lambda x: \"geef voorbeelden\" if (isinstance(x, str) and \"voorbeeld\" in x) else x)\n",
        "\n",
        "df.task = df.task.map(lambda x: x if x in map(lambda x : x.lower(), tasks) else \"anders\")\n",
        "df.domain = df.domain.map(lambda x: x if x in map(lambda x : x.lower(), domains) else \"anders\")\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1719492722560
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Inspect (on prompt and session level) newly introduced tasks, domains or question types (beyond the ones we've specified) "
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# df[~df.task.isin(tasks)]"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1719492746999
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Newly introduced tasks & domains on prompt and session level (used in development to improve the lists)"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df[~df.task.isin(map(lambda x : x.lower(), tasks))].task.value_counts()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1719492755411
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "session_df[~session_df.task.isin(map(lambda x : x.lower(), tasks))].task.value_counts()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1719492765226
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df[~df.domain.isin(map(lambda x: x.lower(), domains))].domain.value_counts()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1719492778906
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "session_df[~session_df.domain.isin(map(lambda x: x.lower(), domains))].domain.value_counts()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1719492783020
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df[~df.question.isin(map(lambda x: x.lower(), questions))].question.value_counts()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1719492786068
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "session_df[~session_df.question.isin(map(lambda x: x.lower(), questions))].question.value_counts()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1719492788382
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inspect risky or harmful"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# pd.set_option('display.max_colwidth', None)\n",
        "\n",
        "df[df[\"risk\"] == True][[\"Prompt\", \"risk\", \"risk_word\", \"harmful\"]]"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1719492791768
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df[df[\"harmful\"] == True][[\"Prompt\", \"risk\", \"risk_word\", \"harmful\"]]"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1719492800832
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Also on session level"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# pd.set_option('display.max_colwidth', None)\n",
        "\n",
        "# session_df[session_df[\"risk\"] == True][[\"Prompt\", \"risk\", \"risk_word\", \"harmful\"]]"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1713799282511
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# pd.set_option('display.max_colwidth', None)\n",
        "\n",
        "# session_df[session_df[\"harmful\"] == True][[\"Prompt\", \"risk\", \"risk_word\", \"harmful\"]]"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1713799283150
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Output into (pretty) html & csv & xsls for manual analysis by domain experts"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# df.to_html(output_file_html)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1719492837965
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pretty_html_table import build_table\n",
        "\n",
        "\n",
        "# Save individual to html file\n",
        "pretty_html_table = build_table(df, \"red_light\")\n",
        "with open(output_file_html.format(level=\"prompt\"), \"w\") as f:\n",
        "    f.write(pretty_html_table)\n",
        "\n",
        "# Save to html file\n",
        "pretty_html_table = build_table(session_df, \"red_light\")\n",
        "with open(output_file_html.format(level=\"session\"), \"w\") as f:\n",
        "    f.write(pretty_html_table)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1719492838794
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv(output_file_csv.format(level=\"prompt\"), index=False)\n",
        "session_df.to_csv(output_file_csv.format(level=\"session\"), index=False)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1719492842781
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with pd.ExcelWriter(output_file_xlsx, engine=\"xlsxwriter\") as writer:\n",
        "    df.to_excel(writer, sheet_name=\"prompts\")\n",
        "    session_df.to_excel(writer, sheet_name=\"convos\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1719492844262
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# A few example plots"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(output_file_csv.format(level=\"prompt\"), index_col=0)\n",
        "session_df = pd.read_csv(output_file_csv.format(level=\"session\"), index_col=0)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1719492850002
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tasks"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://community.plotly.com/t/nested-pie-charts/24011/3"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "task_counts = df.task.value_counts()\n",
        "known_tasks = df.task.unique()\n",
        "\n",
        "values_per_task = [sum([task_counts[subtask] if subtask in task_counts else 0 for subtask in subtasks]) for task, subtasks in task_types.items()]\n",
        "ordered_parents, values_per_task = map(list, zip(*sorted(zip(task_types.keys(), values_per_task), key=lambda x: x[1], reverse=True)))\n",
        "labels = sum([task_types[task] for task in ordered_parents], [])\n",
        "parents = sum([[key] * len(task_types[key]) for key in ordered_parents], [])\n",
        "values = [task_counts[label] if label in known_tasks else 0 for label in labels]\n",
        "# values_per_task = [sum([val for idx, val in enumerate(values) if parents[idx] == task]) for task in task_types.keys()]\n",
        "plotting_values = (values_per_task + values) / sum(values_per_task)\n",
        "\n",
        "colors_original = [\n",
        "    \"#D92720\", \"#EF9120\", \n",
        "    \"#00AEEF\", \n",
        "    \"#00AEEF\", \"#D92720\",\n",
        "    \"#D92720\", \"#EF9120\", \"#00AB4E\", \"#00AEEF\", \"#D92720\", \"00AB4E\"  \n",
        "    ]\n",
        "colors_final = [\"#004699\", \"#949CCC\", \"#53B361\", \"#D6ECD6\", \"#BED200\", \"#F6F6D4\", \"#FF9100\", \"#FFC88E\", \"#EC0000\", \"#FFD4E2\"]\n",
        "# red prominant / move pink on the back\n",
        "colors_final.reverse()\n",
        "colors_final = colors_final[1:] + [colors_final[0]]\n",
        "# colors_ordered = [\"#EC0000\", \"#FF9100\", \"#FFC88E\", \"#F6F6D4\", \"#BED200\", \"#D6ECD6\", \"#53B361\", \"#004699\", \"#949CCC\", \"#FFD4E2\"]\n",
        "\n",
        "trace = go.Sunburst(\n",
        "    labels=ordered_parents + labels,\n",
        "    parents=[\"\"] * len(task_types.keys())  + parents,\n",
        "    values= (values_per_task + values) / sum(values_per_task),\n",
        "    branchvalues=\"total\",\n",
        "    insidetextfont = {\"size\": 200},\n",
        "    outsidetextfont = {\"size\": 200, \"color\": \"#130E1D\"},\n",
        "    marker = {\"line\": {\"width\": 2}, \"colors\": colors_final},\n",
        ")\n",
        "\n",
        "layout = go.Layout(\n",
        "    margin = go.layout.Margin(t=0, l=0, r=0, b=0),\n",
        "    autosize=True\n",
        ")\n",
        "\n",
        "figure = {\n",
        "    'data': [trace],\n",
        "    'layout': layout,\n",
        "}\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1719492858481
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# plotly.offline.iplot(figure)\n",
        "go.Figure(figure, layout={\"width\":5000, \"height\":5000})"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1719492861632
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig = go.Figure(figure)\n",
        "fig.write_html(f\"{input_file}-analyzed-tasks-interactive.html\")\n",
        "fig.write_image(f\"{input_file}-analyzed-tasks-interactive.png\", width=5000, height=5000)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1719492869431
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Domains"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.express as px\n",
        "\n",
        "figure = px.pie(df.domain.value_counts().reset_index(), values='count', names=\"domain\")\n",
        "\n",
        "figure.update_traces(textposition='inside', textinfo='percent+label', textfont_size=200)\n",
        "figure.show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1719492877601
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig = go.Figure(figure)\n",
        "fig.write_html(f\"{input_file}-analyzed-domain-interactive.html\")\n",
        "fig.write_image(f\"{input_file}-analyzed-domain-interactive.png\", width=5000, height=5000)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1719492884484
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Domains (split factual)"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "\n",
        "domain_counts = df.domain.value_counts()\n",
        "common_domains = domain_counts[domain_counts > 1].index\n",
        "\n",
        "domains_fact_plot = sns.catplot(\n",
        "    data=df[df.domain.isin(common_domains)], y=\"domain\", \n",
        "    # hue=\"harmful\",\n",
        "    # hue=\"risk\",\n",
        "    hue=\"factual\",\n",
        "    kind=\"count\",\n",
        "    palette=\"coolwarm\", edgecolor=\".6\",\n",
        ")\n",
        "domains_fact_plot.figure.savefig(f\"{input_file}-analyzed-domains-fact.png\")\n",
        "domains_fact_plot"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1719492971311
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "domain_counts = session_df.domain.value_counts()\n",
        "common_domains = domain_counts[domain_counts > 0].index\n",
        "\n",
        "domains_fact_plot = sns.catplot(\n",
        "    data=session_df[session_df.domain.isin(common_domains)], y=\"domain\", \n",
        "    # hue=\"harmful\",\n",
        "    # hue=\"risk\",\n",
        "    hue=\"factual\",\n",
        "    kind=\"count\",\n",
        "    palette=\"coolwarm\", edgecolor=\".6\",\n",
        ")\n",
        "domains_fact_plot.figure.savefig(f\"{input_file}-analyzed-domains-fact-session.png\")\n",
        "domains_fact_plot"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1719492974788
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Types of questions"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.express as px\n",
        "\n",
        "# figure = px.pie(df.question.value_counts().reset_index(), values='count', names=\"question\")\n",
        "figure = px.pie(df.map(lambda x: \"geen van toepassing\" if pd.isnull(x) or not x else x)[\"question\"].value_counts().reset_index(), values='count', names=\"question\")\n",
        "figure.update_traces(textposition='inside', textinfo='percent+label')\n",
        "figure.show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1719492894813
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "go.Figure(figure).write_html(f\"{input_file}-analyzed-questions-interactive.html\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1719492896633
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Wordclouds based on GPTs free form topic"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
        "import matplotlib.pyplot as plt\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "stopwords = set(list(STOPWORDS) + stopwords.words(\"dutch\"))\n",
        "stopwords.update([\"en\", \"Amsterdam\", \"Amsterdamse\", \"gemeente\"])"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1719492898216
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prompt topics"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \" \".join(df.topic.map(str).str.lower())\n",
        "\n",
        "# Create and generate a word cloud image:\n",
        "wordcloud = WordCloud(stopwords=stopwords, background_color=\"white\", colormap=\"PuRd\", width=1200, height=900).generate(text)\n",
        "\n",
        "# Display the generated image:\n",
        "plt.figure(figsize=(12,9))\n",
        "plt.imshow(wordcloud, interpolation='bilinear')\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1719492900630
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "wordcloud.to_file(f\"{input_file}-wordcloud-prompt.png\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1719492901905
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Session topics"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \" \".join(session_df.topic.map(str).str.lower())\n",
        "\n",
        "# Create and generate a word cloud image:\n",
        "wordcloud = WordCloud(stopwords=stopwords, background_color=\"white\", colormap=\"PuRd\", width=1200, height=900).generate(text)\n",
        "\n",
        "# Display the generated image:\n",
        "plt.figure(figsize=(12,9))\n",
        "plt.imshow(wordcloud, interpolation='bilinear')\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1719492903405
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "wordcloud.to_file(f\"{input_file}-wordcloud-session.png\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1719492904125
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "gen-ai-py39"
    },
    "kernelspec": {
      "name": "gen-ai-py39",
      "language": "python",
      "display_name": "gen-ai-py39"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.18",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      },
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}